{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5YsvJfQvMA1fbqr2gueXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VAC10/C-Application/blob/main/Turkcell_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hFFA5yAulJrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# collab bağlantısı"
      ],
      "metadata": {
        "id": "8tRrTJe5_eqd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDBOLwEU-Dqd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ksMSNXeBCIYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "import urllib\n",
        "\n",
        "import itertools\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns \n",
        "\n",
        "import random, os, glob\n",
        "\n",
        "from imutils import paths \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import shuffle \n",
        "\n",
        "from urllib.request import urlopen\n",
        "\n",
        "#Warningleri kapatmak için kullanilmaktadir.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Model değerlendirme için kullanilacak olan kütüphaneler \n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#Model için kullanılacak olan kütüphaneler \n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping \n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, SpatialDropout2D\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense"
      ],
      "metadata": {
        "id": "jJ-bfs5KFK9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)VERİ SETİNİN OKUNMASI\n",
        "\n",
        ">a)veri seti adresinin collaba gonderilmesi\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lC1evL0PGlYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "id": "a9zt6syyGnjZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "9ac8448c-128a-49b8-c0fe-0cfed2aa3e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b80391d2b2cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path ='/content/drive/MyDrive/Garbage classification/Garbage classification' # bu veri setinin yer aldığı pathin tutulması.."
      ],
      "metadata": {
        "id": "-jykhEZtHgQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#target size ve label etiket değerlerinin belirlenmesi\n",
        "target_size=(224,224)\n",
        "waste_labels ={'cardboard': 0,'glass': 1,'metal': 2, 'paper': 3, 'plastic': 4,'trash': 5} # her bir klasorun ismini kullanarak her bir görsele etiketleme yaptık ve endcode ettik"
      ],
      "metadata": {
        "id": "xV_UWXtOH08x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_datasets(path):\n",
        "    x=[]\n",
        "    labels=[]\n",
        "  \n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Görsellerin bulunduğu dizindeki görüntüyü okuyup etiketlerini oluşturur.\n",
        "\n",
        "    Parametreler:\n",
        "\n",
        "    path: Görsellerin bulunduğu dizini ifade eder.\n",
        "\n",
        "    Return:\n",
        "\n",
        "    x: Görüntülere ait matris bilgilerini tutar.\n",
        "\n",
        "    labels: Görüntünün ait olduğu sınıif bilgisini tutan liste.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Gönderdiğimiz pathdeki görüntüleri listeleyip sıralamaktadır. \n",
        "    image_paths=sorted(list(paths.list_images(path)))\n",
        "\n",
        "    for image_path in image_paths: # Belirtilen pathdeki görüntüler openCV kütüphanesi ile okunmaktadır.\n",
        "        img=cv2.imread(image_path)\n",
        "\n",
        "      # Okunan görüntüler başlangıçta belirlenen target size'a göre yeniden ölçeklendirilir. \n",
        "        img= cv2.resize(img, target_size)\n",
        "\n",
        "      # ölçeklendirilen görüntüler x listesine eklenir.\n",
        "        x.append(img)\n",
        "      # Her bir path '/' ifadesi ile ayrıldığında dönen listenin sondan ikinci elemanı labelı temsil etmektedir.\n",
        "        label=image_path.split(os.path.sep)[-2]\n",
        "  # Yakalanan labelların sayısal değer karşılıklarının olduğu waste labels sözlüğü içerisinden gönderilen key # değerine karşılik value,değeri alınarak label oluşturulur.\n",
        "        labels.append(waste_labels[label])\n",
        "\n",
        "        # Veri seti random bir şekilde karıştırılır.\n",
        "    x, labels=shuffle(x, labels, random_state=42)\n",
        "\n",
        "            # Boyut ve Sinıf Bilgisi raporlanmaktadır. \n",
        "    print (f\"X boyutu: {np.array(x).shape}\") \n",
        "    print(f\"Label sinıf sayıs1: {len(np.unique(labels))} Gözlem sayısı: {len(labels)}\")\n",
        "\n",
        "    return x, labels\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YvbTLnxuJVH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,labels=load_datasets(dir_path)"
      ],
      "metadata": {
        "id": "zFJeI6a4gFwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_img(image_batch, label_batch):\n",
        "    \"\"\"\n",
        "    Veri seti içerisinden görüntü görselleştirir.\n",
        "\n",
        "    Parametreler:\n",
        "\n",
        "    image batch: Görüntülere ait matris bilgilerini tutar.\n",
        "\n",
        "    label batch: Görüntünün ait olduğu sınıf bilgisini tutan liste.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10,10)) \n",
        "    for n in range(10):\n",
        "\n",
        "        ax =plt.subplot (5,5,n+1)\n",
        "        plt.imshow(image_batch[n])\n",
        "\n",
        "        plt.title(np.array(list(waste_labels.keys()))[to_categorical(labels, num_classes=6)[n]==1][0].title()) \n",
        "        plt.axis('off')\n",
        "\n"
      ],
      "metadata": {
        "id": "lqoSz2ffrxsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_img(x,labels)"
      ],
      "metadata": {
        "id": "ZtSjNCOyuAbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)VERİYİ HAZIRLAMA\n"
      ],
      "metadata": {
        "id": "vPo_pgwrogDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train veri seti için bir generator tanımlıyoruz\n",
        "train=ImageDataGenerator(horizontal_flip=True,# görüntüyü rastgele yatay olarak çeviriir\n",
        "                         vertical_flip=True,# görüntüyü rastgele dikey olarak çeviriir\n",
        "                         validation_split=0.1,# test veri setinin oranı\n",
        "                         rescale=1./255,#verileri sağlanan değerlere göre yeniden ölçeklendirir \n",
        "                         shear_range=0.1, #görüntüye eğim verir\n",
        "                         zoom_range=0.1,\n",
        "                         width_shift_range=0.1,\n",
        "                         height_shift_range=0.1) # verisetimizde bulunan görselleri görüntü çeşitlendirme teknikleri uygulayark gerçek dünya özelliklerini ekleyecez\n",
        "                         \n",
        "##test veri seti için bir generator tanımlıyoruz \n",
        "\n",
        "test=ImageDataGenerator( \n",
        "                         rescale=1/255,\n",
        "                         validation_split=0.1)\n",
        "                         \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0kAGF3Osom7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator=train.flow_from_directory(directory=dir_path,\n",
        "                                        target_size=(target_size),                                        \n",
        "                                        class_mode='categorical',\n",
        "                                        subset='training')\n",
        "\n",
        "test_generator=test.flow_from_directory(directory=dir_path,\n",
        "                                        target_size=(target_size), \n",
        "                                        batch_size=251,\n",
        "                                        class_mode='categorical',\n",
        "                                        subset='validation')\n"
      ],
      "metadata": {
        "id": "o5DwKY2eveyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "flattena olan kadar kısımda ben resmimin öz niteliklerini\n",
        "çıkarıyorum. conv ile filtreyle üzerinde gezerek resimlerimi tam olarak algılamaya\n",
        "çalışıyorum pooling ile boyutunu düşürüyorum.\n",
        "flattendan sonra ise öğrenme kısmımı oluşturuyorum \n",
        "yani nöromlarımı oluşturuyorum ve dropout yaparak overfittingin önüne geçiyorum.\n",
        "\"\"\"\n",
        "model=Sequential()\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3),padding=\"same\",input_shape=(224,224,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=2,strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\",input_shape=(224,224,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=2,strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3),padding=\"same\",input_shape=(224,224,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=2,strides=(2,2)))\n",
        "\n",
        "model.add(Flatten())#yapay sinir ağları giriş verilerini tek boyutlu diziden alır\n",
        "# ama pooling ve evrişim katmanında veriler matris olarak gelir. flatten ile biz bu katmanlardan gelen verileri tek boyutlu diziye çeviririz. \n",
        "\n",
        "model.add(Dense(units=64,activation=\"relu\"))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Dense(units=32,activation=\"relu\"))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Dense(units=6,activation=\"softmax\")) # 6 sınıflı bir sınıflandırma problemimiz var \n",
        "#ikiden fazla sınıflandırma olduğundan dolayı softmax kullanırım\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GdLrgxJpCSkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL ÖZETİ\n"
      ],
      "metadata": {
        "id": "hJur0BMqVQaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "eERcDbIMVTLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPTİMİZASYON VE DEĞERLENDİRME METRİKLERİNİN AYARLANMASI"
      ],
      "metadata": {
        "id": "hvFTp3TcXmu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",# ikiden fazla sınıf olduğundan categoircal kullandım 2 tane olaydı binary cross kullanılırdı\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),\"acc\"]\n",
        "              )"
      ],
      "metadata": {
        "id": "cLX3dFj8XtD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[EarlyStopping(monitor=\"val_loss\",patience=50,verbose=1,mode=\"min\"),# model ezberlemeye başladığı an durdur(50 epochtan sonra) early stopping\n",
        "           #monitorde ise modelin ezberlemeye başladığını hangi metrikle anlayacağız demektir\n",
        "           ModelCheckpoint(filepath=\"mymodel.h5\",monitor=\"val_loss\",mode=\"min\",save_best_only=True,save_weights_only=False,verbose=1) # iterasyonda yakalanan en iyi modelin kaydedilmesi\n",
        "]"
      ],
      "metadata": {
        "id": "ewTU8NfCaG1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELİN EĞİTİLMESİ\n"
      ],
      "metadata": {
        "id": "609cZEJhc6qA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit_generator(generator=train_generator,\n",
        "                            epochs=100,\n",
        "                            validation_data=test_generator,\n",
        "                            callbacks=callbacks,\n",
        "                            workers=4, # paralel olarak gruplar hesaplanır(donanımsal parametredir)\n",
        "                            steps_per_epoch=2275/31,# her epochta 71 adımda model eğitimi gerçekleşecek\n",
        "                            validation_steps=252/31)\n",
        "\n"
      ],
      "metadata": {
        "id": "cEY_ALxnc-xR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}